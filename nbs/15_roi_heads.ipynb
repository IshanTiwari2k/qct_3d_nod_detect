{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389291f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp roi_heads\n",
    "#| export\n",
    "from torch import nn\n",
    "import torch\n",
    "from qct_3d_nod_detect.structures import Instances3D, pairwise_iou_3d\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "def add_ground_truth_to_proposals_3d(\n",
    "    targets: List[Instances3D],\n",
    "    proposals: List[Instances3D],\n",
    ") -> List[Instances3D]:\n",
    "    \"\"\"\n",
    "    Augment proposals with ground-truth boxes.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(targets) == len(proposals)\n",
    "\n",
    "    new_proposals = []\n",
    "\n",
    "    for proposals_per_image, targets_per_image in zip(proposals, targets):\n",
    "\n",
    "        if len(targets_per_image) == 0:\n",
    "            new_proposals.append(proposals_per_image)\n",
    "            continue\n",
    "\n",
    "        # Clone to avoid in-place modification\n",
    "        proposals_per_image = proposals_per_image.clone()\n",
    "\n",
    "        gt_boxes = targets_per_image.gt_boxes\n",
    "        device = gt_boxes.tensor.device\n",
    "\n",
    "        # Create new Instances3D for GT boxes\n",
    "        gt_proposals = Instances3D(proposals_per_image.image_size)\n",
    "        gt_proposals.proposal_boxes = gt_boxes\n",
    "\n",
    "        # Objectness logits: high confidence for GT\n",
    "        gt_proposals.objectness_logits = torch.ones(\n",
    "            len(gt_boxes), device=device\n",
    "        )\n",
    "\n",
    "        # Concatenate proposals\n",
    "        proposals_per_image = Instances3D.cat(\n",
    "            [proposals_per_image, gt_proposals]\n",
    "        )\n",
    "\n",
    "        new_proposals.append(proposals_per_image)\n",
    "\n",
    "    return new_proposals\n",
    "\n",
    "def subsample_labels(\n",
    "    labels: torch.Tensor,\n",
    "    num_samples: int,\n",
    "    positive_fraction: float,\n",
    "    num_classes: int,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        labels (Tensor): shape (N,), values in:\n",
    "            [0, num_classes) = foreground\n",
    "            num_classes      = background\n",
    "            -1               = ignore\n",
    "        num_samples (int): total number of samples\n",
    "        positive_fraction (float): fraction of positives\n",
    "        num_classes (int): number of foreground classes\n",
    "\n",
    "    Returns:\n",
    "        sampled_fg_idxs (Tensor)\n",
    "        sampled_bg_idxs (Tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    # foreground: [0, num_classes)\n",
    "    fg_mask = (labels >= 0) & (labels < num_classes)\n",
    "    fg_idxs = torch.nonzero(fg_mask).squeeze(1)\n",
    "\n",
    "    # background: == num_classes\n",
    "    bg_mask = labels == num_classes\n",
    "    bg_idxs = torch.nonzero(bg_mask).squeeze(1)\n",
    "\n",
    "    num_fg = int(num_samples * positive_fraction)\n",
    "    num_fg = min(num_fg, fg_idxs.numel())\n",
    "\n",
    "    num_bg = num_samples - num_fg\n",
    "    num_bg = min(num_bg, bg_idxs.numel())\n",
    "\n",
    "    # Random sampling\n",
    "    perm_fg = torch.randperm(fg_idxs.numel(), device=labels.device)[:num_fg]\n",
    "    perm_bg = torch.randperm(bg_idxs.numel(), device=labels.device)[:num_bg]\n",
    "\n",
    "    sampled_fg_idxs = fg_idxs[perm_fg]\n",
    "    sampled_bg_idxs = bg_idxs[perm_bg]\n",
    "\n",
    "    return sampled_fg_idxs, sampled_bg_idxs\n",
    "\n",
    "class ROIHeads3D(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            num_classes: int,\n",
    "            batch_size_per_image: int,\n",
    "            positive_fraction: float,\n",
    "            proposal_matcher,\n",
    "            proposal_append_gt: bool,\n",
    "            roi_pooler,\n",
    "            box_head,\n",
    "            box_predictor,\n",
    "            is_training,\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size_per_image = batch_size_per_image\n",
    "        self.positive_fraction = positive_fraction\n",
    "        self.proposal_matcher = proposal_matcher\n",
    "        self.proposal_append_gt = proposal_append_gt\n",
    "\n",
    "        self.roi_pooler = roi_pooler\n",
    "        self.box_head = box_head\n",
    "        self.box_predictor = box_predictor\n",
    "        self.training = is_training\n",
    "\n",
    "    def _sample_proposals(\n",
    "            self,\n",
    "            matched_idxs: torch.Tensor,\n",
    "            matched_labels: torch.Tensor,\n",
    "            gt_classes: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        has_gt = gt_classes.numel() > 0\n",
    "\n",
    "        if has_gt:\n",
    "            gt_classes = gt_classes[matched_idxs]\n",
    "            gt_classes[matched_labels == 0] = self.num_classes\n",
    "            gt_classes[matched_labels == -1] = -1\n",
    "        else:\n",
    "            gt_classes = torch.zeros_like(matched_idxs) + self.num_classes\n",
    "\n",
    "        sampled_fg_idxs, sampled_bg_idxs = subsample_labels(\n",
    "            gt_classes,\n",
    "            self.batch_size_per_image,\n",
    "            self.positive_fraction,\n",
    "            self.num_classes\n",
    "        )\n",
    "\n",
    "        sampled_idxs = torch.cat([sampled_fg_idxs, sampled_bg_idxs], dim=0)\n",
    "        return sampled_idxs, gt_classes[sampled_idxs]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def label_and_sample_proposals(\n",
    "        self,\n",
    "        proposals: List[Instances3D],\n",
    "        targets: List[Instances3D],\n",
    "    ) -> List[Instances3D]:\n",
    "        \n",
    "        if self.proposal_append_gt:\n",
    "            proposals = add_ground_truth_to_proposals_3d(targets, proposals)\n",
    "\n",
    "        proposals_with_gt = []\n",
    "\n",
    "        for proposal_per_image, targets_per_image in zip(proposals, targets):\n",
    "\n",
    "            has_gt = len(targets_per_image) > 0\n",
    "\n",
    "            if has_gt:\n",
    "                match_quality_matrix = pairwise_iou_3d(\n",
    "                    targets_per_image.gt_boxes,\n",
    "                    proposal_per_image.proposal_boxes\n",
    "                )\n",
    "\n",
    "                matched_idxs, matched_labels = self.proposal_matcher(match_quality_matrix)\n",
    "\n",
    "            else:\n",
    "                device = proposal_per_image.proposal_boxes.tensor.device\n",
    "                matched_idxs = torch.zeros(\n",
    "                    len(proposal_per_image), dtype=torch.int64, device=device\n",
    "\n",
    "                )\n",
    "\n",
    "                matched_labels = torch.zeros_like(matched_idxs)\n",
    "\n",
    "            sampled_idxs, gt_classes = self._sample_proposals(\n",
    "                matched_idxs,\n",
    "                matched_labels,\n",
    "                targets_per_image.gt_classes if has_gt else torch.empty(0),\n",
    "            )\n",
    "\n",
    "            proposals_per_image = proposals_per_image[sampled_idxs]\n",
    "            proposal_per_image.gt_classes = gt_classes\n",
    "\n",
    "            if has_gt:\n",
    "                sampled_targets = matched_idxs[sampled_idxs]\n",
    "                proposal_per_image.gt_boxes = targets_per_image.gt_boxes[sampled_targets]\n",
    "\n",
    "            proposals_with_gt.append(proposals_per_image)\n",
    "\n",
    "        return proposals_with_gt\n",
    "    \n",
    "    def forward(\n",
    "            self,\n",
    "            features: Dict[str, torch.Tensor],\n",
    "            proposals: List[Instances3D],\n",
    "            targets: Optional[List[Instances3D]] = None,\n",
    "    ):\n",
    "        \n",
    "        if self.training:\n",
    "            assert targets is not None\n",
    "            proposals = self.label_and_sample_proposals(proposals, targets)\n",
    "\n",
    "        box_features = self.roi_pooler(features, proposals)\n",
    "        box_features = self.box_head(box_features)\n",
    "\n",
    "        predictions = self.box_predictor(box_features)\n",
    "\n",
    "        if self.training:\n",
    "            return self.box_predictor.losses(predictions, proposals)\n",
    "        else:\n",
    "            return self.box_predictor.inference(predictions, proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab79a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
