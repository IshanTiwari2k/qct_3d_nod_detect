{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350447f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp faster_rcnn\n",
    "#| export\n",
    "from typing import List, Union, Tuple, Dict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from qct_3d_nod_detect.box_regression import _dense_box_regression_loss_3d\n",
    "from qct_3d_nod_detect.structures import Boxes3D, Instances3D\n",
    "from qct_3d_nod_detect.layers import nonzero_tuple\n",
    "import torch.nn.functional as F\n",
    "from qct_3d_nod_detect.proposal_utils import batched_nms_3d\n",
    "\n",
    "def fast_rcnn_inference_3d(\n",
    "    boxes: List[torch.Tensor],\n",
    "    scores: List[torch.Tensor],\n",
    "    volume_shapes: List[Tuple[int, int, int]],\n",
    "    score_thresh: float,\n",
    "    nms_thresh: float,\n",
    "    topk_per_image: int,\n",
    "):\n",
    "    results = [\n",
    "        fast_rcnn_inference_single_image_3d(\n",
    "            boxes_per_image,\n",
    "            scores_per_image,\n",
    "            volume_shape,\n",
    "            score_thresh,\n",
    "            nms_thresh,\n",
    "            topk_per_image,\n",
    "        )\n",
    "        \n",
    "        for boxes_per_image, scores_per_image, volume_shape\n",
    "        in zip(boxes, scores, volume_shapes)\n",
    "    ]\n",
    "\n",
    "    return [r[0] for r in results], [r[1] for r in results]\n",
    "\n",
    "def fast_rcnn_inference_single_image_3d(\n",
    "    boxes: torch.Tensor,\n",
    "    scores: torch.Tensor,\n",
    "    volume_shape: Tuple[int, int, int],\n",
    "    score_thresh: float,\n",
    "    nms_thresh: float,\n",
    "    topk_per_image: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    boxes: (R, K*6) or (R, 6)\n",
    "    scores: (R, K+1)\n",
    "    volume_shape: (D, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove invalid rows\n",
    "    valid_mask = torch.isfinite(boxes).all(dim=1) & torch.isfinite(scores).all(dim=1)\n",
    "    if not valid_mask.all():\n",
    "        boxes = boxes[valid_mask]\n",
    "        scores = scores[valid_mask]\n",
    "\n",
    "    scores = scores[:, :-1]  # remove background\n",
    "    num_bbox_reg_classes = boxes.shape[1] // 6\n",
    "\n",
    "    # Reshape boxes\n",
    "    boxes = Boxes3D(boxes.reshape(-1, 6))\n",
    "    boxes.clip(volume_shape)\n",
    "    boxes = boxes.tensor.view(-1, num_bbox_reg_classes, 6)  # R x C x 6\n",
    "\n",
    "    # 1. Score thresholding\n",
    "    filter_mask = scores > score_thresh  # R x K\n",
    "    filter_inds = filter_mask.nonzero(as_tuple=False)  # (N, 2)\n",
    "\n",
    "    if num_bbox_reg_classes == 1:\n",
    "        boxes = boxes[filter_inds[:, 0], 0]\n",
    "    else:\n",
    "        boxes = boxes[filter_mask]\n",
    "\n",
    "    scores = scores[filter_mask]\n",
    "\n",
    "    # 2. Class-wise 3D NMS\n",
    "    keep = batched_nms_3d(\n",
    "        boxes,\n",
    "        scores,\n",
    "        filter_inds[:, 1],\n",
    "        nms_thresh,\n",
    "    )\n",
    "\n",
    "    if topk_per_image >= 0:\n",
    "        keep = keep[:topk_per_image]\n",
    "\n",
    "    boxes = boxes[keep]\n",
    "    scores = scores[keep]\n",
    "    filter_inds = filter_inds[keep]\n",
    "\n",
    "    # Output container (Detectron2-style)\n",
    "    result = {\n",
    "        \"pred_boxes\": boxes,\n",
    "        \"scores\": scores,\n",
    "        \"pred_classes\": filter_inds[:, 1],\n",
    "    }\n",
    "\n",
    "    return result, filter_inds[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ca7ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#| export\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFasterRCNNOutputLayers3D\u001b[39;00m(\u001b[43mnn\u001b[49m.Module):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m      5\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m      6\u001b[39m         input_dim: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m         smooth_l1_beta: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m,\n\u001b[32m     17\u001b[39m     ):\n\u001b[32m     19\u001b[39m         \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "class FasterRCNNOutputLayers3D(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        num_classes: int,\n",
    "        *,\n",
    "        box2box_transform,\n",
    "        cls_agnostic_bbox_reg: bool = False,\n",
    "        test_score_thresh: float = 0.05,\n",
    "        test_nms_thresh: float = 0.5,\n",
    "        test_topk_per_image: int = 100,\n",
    "        loss_weight: Union[float, Dict[str, float]] = 1.0,\n",
    "        box_reg_loss_type: str = \"smooth_l1\",\n",
    "        smooth_l1_beta: float = 0.0,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.box2box_transform = box2box_transform\n",
    "        self.cls_agnostic_bbox_reg = cls_agnostic_bbox_reg\n",
    "        self.bbox_reg_loss_type = box_reg_loss_type\n",
    "        self.smooth_l1_beta = smooth_l1_beta\n",
    "\n",
    "        # ---- heads ----\n",
    "        self.cls_score = nn.Linear(input_dim, num_classes + 1)\n",
    "        num_bbox_reg_classes = 1 if cls_agnostic_bbox_reg else num_classes\n",
    "        self.bbox_pred = nn.Linear(input_dim, num_bbox_reg_classes * 6)\n",
    "\n",
    "        # ---- init ----\n",
    "        nn.init.normal_(self.cls_score.weight, std=0.01)\n",
    "        nn.init.normal_(self.bbox_pred.weight, std=0.001)\n",
    "        nn.init.constant_(self.cls_score.bias, 0)\n",
    "        nn.init.constant_(self.bbox_pred.bias, 0)\n",
    "\n",
    "        self.test_score_thresh = test_score_thresh\n",
    "        self.test_nms_thresh = test_nms_thresh\n",
    "        self.test_topk_per_image = test_topk_per_image\n",
    "\n",
    "        if isinstance(loss_weight, float):\n",
    "            loss_weight = {\"loss_cls\": loss_weight, \"loss_box_reg\": loss_weight}\n",
    "\n",
    "        self.loss_weight = loss_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (N, C) or (N, C, ...)\n",
    "        Returns:\n",
    "            scores: (N, K + 1)\n",
    "            proposal_deltas: (N, 6) or (N, K * 6)\n",
    "        \"\"\"\n",
    "\n",
    "        if x.dim() > 2:\n",
    "            x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        scores = self.cls_score(x)\n",
    "        proposal_deltas = self.bbox_pred(x)\n",
    "\n",
    "        return scores, proposal_deltas\n",
    "\n",
    "    def inference(\n",
    "        self,\n",
    "        predictions: Tuple[torch.Tensor, torch.Tensor],\n",
    "        proposals: List[Instances3D],\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            results: List[Instances3D]\n",
    "            kept_indices: List[Tensor]\n",
    "        \"\"\"\n",
    "\n",
    "        boxes = self.predict_boxes(predictions, proposals)\n",
    "        scores = self.predict_probs(predictions, proposals)\n",
    "\n",
    "        image_shapes = [p.image_size for p in proposals]\n",
    "\n",
    "        return fast_rcnn_inference_3d(\n",
    "            boxes,\n",
    "            scores,\n",
    "            image_shapes,\n",
    "            self.test_score_thresh,\n",
    "            self.test_nms_thresh,\n",
    "            self.test_topk_per_image,\n",
    "        )\n",
    "\n",
    "    def box_reg_loss(\n",
    "            self, \n",
    "            proposal_boxes,\n",
    "            gt_boxes,\n",
    "            pred_deltas,\n",
    "            gt_classes\n",
    "    ):\n",
    "\n",
    "        box_dim = proposal_boxes.shape[1] # 6\n",
    "        fg_inds = nonzero_tuple((gt_classes >= 0) & (gt_classes < self.num_classes))[0]\n",
    "        fg_mask = torch.ones(len(fg_inds), dtype=torch.bool, device=proposal_boxes.device)\n",
    "\n",
    "        if fg_inds.numel() == 0:\n",
    "            return pred_deltas.sum() * 0.0\n",
    "        \n",
    "        if pred_deltas.shape[1] == box_dim:\n",
    "            fg_pred_deltas = pred_deltas[fg_inds]\n",
    "        else:\n",
    "            fg_pred_deltas = pred_deltas.view(-1, self.num_classes, box_dim)[\n",
    "                fg_inds, gt_classes[fg_inds]\n",
    "            ]\n",
    "\n",
    "        loss_bbox_reg = _dense_box_regression_loss_3d(\n",
    "            [proposal_boxes[fg_inds]],\n",
    "            self.box2box_transform,\n",
    "            [fg_pred_deltas.unsqueeze(0)],\n",
    "            [gt_boxes[fg_inds]],\n",
    "            fg_mask.unsqueeze(0),\n",
    "            self.bbox_reg_loss_type,\n",
    "            self.smooth_l1_beta,\n",
    "        )\n",
    "        \n",
    "        return loss_bbox_reg / max(gt_classes.numel(), 1.0)\n",
    "\n",
    "    def losses(\n",
    "            self,\n",
    "            predictions,\n",
    "            proposals,\n",
    "    ):\n",
    "        \n",
    "        scores, proposal_deltas = predictions\n",
    "\n",
    "        gt_classes = torch.cat([p.gt_classes for p in proposals], dim=0)\n",
    "        proposal_boxes = torch.cat([p.proposal_boxes.tensor for p in proposals], dim=0)\n",
    "        gt_boxes = torch.cat([p.gt_boxes.tensor for p in proposals], dim=0)\n",
    "\n",
    "        valid_mask = gt_classes >= 0\n",
    "        loss_cls = F.cross_entropy(scores[valid_mask], gt_classes[valid_mask])\n",
    "\n",
    "        loss_box_reg = self.box_reg_loss(\n",
    "            proposal_boxes,\n",
    "            gt_boxes,\n",
    "            proposal_deltas,\n",
    "            gt_classes\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n",
    "            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n",
    "        }\n",
    "\n",
    "    def predict_boxes(\n",
    "            self,\n",
    "            predictions: Tuple[torch.Tensor, torch.Tensor],\n",
    "            proposals: List[Instances3D],\n",
    "    ):\n",
    "\n",
    "        if not len(proposals):\n",
    "            return []\n",
    "        \n",
    "        _, proposal_deltas = predictions\n",
    "        proposal_boxes = torch.cat([p.proposal_boxes.tensor for p in proposals], dim=0)\n",
    "\n",
    "        pred_boxes = self.box2box_transform.apply_deltas(\n",
    "            proposal_deltas, proposal_boxes\n",
    "        )  # (N, K*6) or (N, 6)\n",
    "\n",
    "        num_props = [len(p) for p in proposals]\n",
    "        return pred_boxes.split(num_props)\n",
    "\n",
    "    def predict_probs(\n",
    "            self,\n",
    "            predictions: Tuple[torch.Tensor, torch.Tensor],\n",
    "            proposals: List[Instances3D],\n",
    "    ):\n",
    "\n",
    "        if not len(proposals):\n",
    "            return []\n",
    "\n",
    "        scores, _ = predictions\n",
    "        num_props = [len(p) for p in proposals]\n",
    "        probs = torch.softmax(scores, dim=-1)\n",
    "        return probs.split(num_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc920f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qct_nod_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
