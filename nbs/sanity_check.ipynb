{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6bd870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Anchors per level: [1, 1, 1]\n",
      "Total proposals: 25\n",
      "ROIPooler3D created with pooler type: ROIALign3DV2\n",
      "Levels: 3 → 5\n",
      "torch.Size([25, 256, 7, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from qct_3d_nod_detect.anchor_generator_3d import DefaultAnchorGenerator3D\n",
    "from qct_3d_nod_detect.box_regression import Box3DTransform\n",
    "from qct_3d_nod_detect.matcher import Matcher\n",
    "from qct_3d_nod_detect.rpn import RPN3D, StandardRPNHead3d\n",
    "from qct_3d_nod_detect.structures import Boxes3D, Instances3D\n",
    "from qct_3d_nod_detect.poolers import ROIPooler3D\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "#  Reuse your existing setup\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "N = 2\n",
    "C = 256\n",
    "\n",
    "image_sizes = [(32, 128, 128), (32, 128, 128)]\n",
    "\n",
    "features = {\n",
    "    \"p3\": torch.randn(N, C, 16, 64, 64, device=device),   # stride ~8\n",
    "    \"p4\": torch.randn(N, C,  8, 32, 32, device=device),   # stride ~16\n",
    "    \"p5\": torch.randn(N, C,  4, 16, 16, device=device),   # stride ~32\n",
    "}\n",
    "\n",
    "class ImageList3D:\n",
    "    def __init__(self, image_sizes):\n",
    "        self.image_sizes = image_sizes\n",
    "\n",
    "images = ImageList3D(image_sizes)\n",
    "\n",
    "gt_instances = []\n",
    "\n",
    "for i in range(N):\n",
    "    inst = Instances3D(image_sizes[i])\n",
    "\n",
    "    inst.gt_boxes = Boxes3D(\n",
    "        torch.tensor(\n",
    "            [\n",
    "                [10, 20, 5, 40, 60, 20],\n",
    "                [50, 40, 10, 90, 100, 30]\n",
    "            ],\n",
    "            dtype=torch.float32,\n",
    "            device=device\n",
    "        )\n",
    "    )\n",
    "\n",
    "    gt_instances.append(inst)\n",
    "\n",
    "anchor_generator_3d = DefaultAnchorGenerator3D(\n",
    "    sizes=[[2], [4], [8]],\n",
    "    aspect_ratios_3d=[[(1.0, 1.0)], [(1.0, 1.0)], [(1.0, 1.0)]],\n",
    "    strides=[8, 16, 32],\n",
    "    offset=0.5,\n",
    ").to(device)\n",
    "\n",
    "print(\"Anchors per level:\", anchor_generator_3d.num_cell_anchors)\n",
    "\n",
    "box3d2box3d_transform = Box3DTransform(\n",
    "    weights=(1.0, 1.0, 1.0, 1.0, 1.0, 1.0),\n",
    "    scale_clamp=math.log(1000.0),\n",
    ")\n",
    "\n",
    "num_anchors = anchor_generator_3d.num_cell_anchors[0]  # same for all levels\n",
    "rpn_head_3d = StandardRPNHead3d(\n",
    "    in_channels=C,\n",
    "    num_anchors=num_anchors,\n",
    "    box_dim=6,\n",
    ").to(device)\n",
    "\n",
    "anchor_matcher = Matcher(\n",
    "    thresholds=[0.3, 0.7],\n",
    "    labels=[0, -1, 1],\n",
    "    allow_low_quality_matches=True,\n",
    ")\n",
    "\n",
    "rpn = RPN3D(\n",
    "    in_features=[\"p3\", \"p4\", \"p5\"],\n",
    "    head=rpn_head_3d,\n",
    "    anchor_generator=anchor_generator_3d,\n",
    "    anchor_matcher=anchor_matcher,\n",
    "    box3d_transform=box3d2box3d_transform,\n",
    "    batch_size_per_image=256,\n",
    "    positive_fraction=0.5,\n",
    "    pre_nms_topk=(200, 100),\n",
    "    post_nms_topk=(100, 50),\n",
    "    nms_thresh=0.5,\n",
    "    min_box_size=2.0,\n",
    "    box_reg_loss_type=\"smooth_l1\",\n",
    "    smooth_l1_beta=0.0,\n",
    ").to(device)\n",
    "\n",
    "rpn.eval()\n",
    "with torch.no_grad():\n",
    "    proposals, losses = rpn(images, features, gt_instances)\n",
    "\n",
    "total_proposals = sum(len(p) for p in proposals)\n",
    "print(f\"Total proposals: {total_proposals}\")\n",
    "\n",
    "pooler = ROIPooler3D(\n",
    "    output_size     = (7, 7, 7),\n",
    "    scales          = [1/8.0, 1/16.0, 1/32.0],   # must match feature strides\n",
    "    sampling_ratio  = 0,                         # your impl ignores it anyway\n",
    "    pooler_type     = \"ROIALign3DV2\",            # or \"ROIAlign3D\" or \"ROIPool3D\"\n",
    "    canonical_box_size = 32.0,                   # smaller than 224 — your volumes are tiny\n",
    "    canonical_level = 1,                         # adjust depending on how you number levels\n",
    ").to(device)\n",
    "\n",
    "print(\"ROIPooler3D created with pooler type:\", pooler.pooler_type)\n",
    "print(\"Levels:\", pooler.min_level, \"→\", pooler.max_level)\n",
    "\n",
    "multi_scale_features = [features[\"p3\"], features[\"p4\"], features[\"p5\"]]\n",
    "\n",
    "proposal_boxes_list = [inst.proposal_boxes for inst in proposals]\n",
    "pooled = pooler(\n",
    "    x          = multi_scale_features,\n",
    "    box_lists  = proposal_boxes_list\n",
    ")\n",
    "\n",
    "print(pooled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a8ffcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c8f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qct_nod_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
