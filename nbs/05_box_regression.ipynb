{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abf94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp box_regression\n",
    "#| export\n",
    "from typing import Tuple, List, Union\n",
    "import torch\n",
    "from qct_3d_nod_detect.structures import Boxes3D\n",
    "from fvcore.nn import smooth_l1_loss\n",
    "\n",
    "class Box3DTransform:\n",
    "\n",
    "    def __init__(\n",
    "        self, weights: Tuple[float, float, float, float, float, float], scale_clamp: float\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            weights (6-element tuple): Scaling factors that are applied to the\n",
    "                (dx, dy, dz, dw, dh, dd) deltas. In Fast R-CNN, these were originally set\n",
    "                such that the deltas have unit variance; now they are treated as\n",
    "                hyperparameters of the system.\n",
    "            scale_clamp (float): When predicting deltas, the predicted box scaling\n",
    "                factors (dw and dh) are clamped such that they are <= scale_clamp.\n",
    "        \"\"\"\n",
    "\n",
    "        self.weights = weights\n",
    "        self.scale_clamp = scale_clamp\n",
    "    \n",
    "    def get_deltas(self, src_boxes, target_boxes):\n",
    "\n",
    "        \"\"\"\n",
    "        Get box regression transformation deltas (dx, dy, dz, dw, dh, dd) that can be used\n",
    "        to transform the `src_boxes` into the `target_boxes`. That is, the relation\n",
    "        ``target_boxes == self.apply_deltas(deltas, src_boxes)`` is true (unless\n",
    "        any delta is too large and is clamped).\n",
    "\n",
    "        Args:\n",
    "            src_boxes (Tensor): source boxes, e.g., object proposals\n",
    "            target_boxes (Tensor): target of the transformation, e.g., ground-truth\n",
    "                boxes.\n",
    "        \"\"\"\n",
    "\n",
    "        assert isinstance(src_boxes, torch.Tensor), type(src_boxes)\n",
    "        assert isinstance(target_boxes, torch.Tensor), type(target_boxes)\n",
    "\n",
    "        src_widths = src_boxes[:, 3] - src_boxes[:, 0] # x\n",
    "        src_heights = src_boxes[:, 4] - src_boxes[:, 1] # y\n",
    "        src_depths = src_boxes[:, 5] - src_boxes[:, 2] # z\n",
    "\n",
    "        src_ctr_x = src_boxes[:, 0] + 0.5*src_widths\n",
    "        src_ctr_y = src_boxes[:, 1] + 0.5*src_heights\n",
    "        src_ctr_z = src_boxes[:, 2] + 0.5*src_depths\n",
    "\n",
    "        target_widths = target_boxes[:, 3] - target_boxes[:, 0] \n",
    "        target_heights = target_boxes[:, 4] - target_boxes[:, 1] \n",
    "        target_depths = target_boxes[:, 5] - target_boxes[:, 2]\n",
    "\n",
    "        target_ctr_x = target_boxes[:, 0] + 0.5 * target_widths\n",
    "        target_ctr_y = target_boxes[:, 1] + 0.5 * target_heights\n",
    "        target_ctr_z = target_boxes[:, 2] + 0.5 * target_depths\n",
    "\n",
    "        wx, wy, wz, ww, wh, wd = self.weights\n",
    "\n",
    "        dx = wx * (target_ctr_x - src_ctr_x) / src_widths\n",
    "        dy = wy * (target_ctr_y - src_ctr_y) / src_heights\n",
    "        dz = wz * (target_ctr_z - src_ctr_z) / src_depths\n",
    "\n",
    "        dw = ww * torch.log(target_widths / src_widths)\n",
    "        dh = wh * torch.log(target_heights / src_heights)\n",
    "        dd = wd * torch.log(target_depths / src_depths)\n",
    "\n",
    "        deltas = torch.stack((dx, dy, dz, dw, dh, dd), dim=1)\n",
    "\n",
    "        # Safety check\n",
    "        assert (src_widths > 0).all().item(),  \"Invalid source box widths\"\n",
    "        assert (src_heights > 0).all().item(), \"Invalid source box heights\"\n",
    "        assert (src_depths > 0).all().item(),  \"Invalid source box depths\"\n",
    "\n",
    "        return deltas\n",
    "\n",
    "    def apply_deltas(self, deltas: torch.Tensor, boxes: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        \"\"\"\n",
    "        Apply predicted deltas to boxes to obtain refined predictions.\n",
    "\n",
    "        Args:\n",
    "            deltas (Tensor): predicted deltas, shape (N, K*6) where K is number of predictions per box\n",
    "            boxes (Tensor): source boxes, shape (N, 6)\n",
    "\n",
    "        Returns:\n",
    "            pred_boxes (Tensor): transformed boxes, same shape as input boxes but reshaped\n",
    "        \"\"\"\n",
    "\n",
    "        deltas = deltas.float()  # ensure fp32 for numerical stability\n",
    "        boxes = boxes.to(deltas.dtype)\n",
    "\n",
    "        widths  = boxes[:, 3] - boxes[:, 0]\n",
    "        heights = boxes[:, 4] - boxes[:, 1]\n",
    "        depths  = boxes[:, 5] - boxes[:, 2]\n",
    "\n",
    "        ctr_x = boxes[:, 0] + 0.5 * widths\n",
    "        ctr_y = boxes[:, 1] + 0.5 * heights\n",
    "        ctr_z = boxes[:, 2] + 0.5 * depths\n",
    "\n",
    "        wx, wy, wz, ww, wh, wd = self.weights\n",
    "\n",
    "        # Un-weight deltas\n",
    "        dx = deltas[:, 0::6] / wx\n",
    "        dy = deltas[:, 1::6] / wy\n",
    "        dz = deltas[:, 2::6] / wz\n",
    "        dw = deltas[:, 3::6] / ww\n",
    "        dh = deltas[:, 4::6] / wh\n",
    "        dd = deltas[:, 5::6] / wd\n",
    "\n",
    "        # Clamp scale factors to prevent explosion\n",
    "        dw = torch.clamp(dw, max=self.scale_clamp)\n",
    "        dh = torch.clamp(dh, max=self.scale_clamp)\n",
    "        dd = torch.clamp(dd, max=self.scale_clamp)\n",
    "\n",
    "        # Apply transformation\n",
    "        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n",
    "        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n",
    "        pred_ctr_z = dz * depths[:, None]  + ctr_z[:, None]\n",
    "\n",
    "        pred_w = torch.exp(dw) * widths[:, None]\n",
    "        pred_h = torch.exp(dh) * heights[:, None]\n",
    "        pred_d = torch.exp(dd) * depths[:, None]\n",
    "\n",
    "        # Convert back to corner coordinates\n",
    "        x0 = pred_ctr_x - 0.5 * pred_w\n",
    "        y0 = pred_ctr_y - 0.5 * pred_h\n",
    "        z0 = pred_ctr_z - 0.5 * pred_d\n",
    "        x1 = pred_ctr_x + 0.5 * pred_w\n",
    "        y1 = pred_ctr_y + 0.5 * pred_h\n",
    "        z1 = pred_ctr_z + 0.5 * pred_d\n",
    "\n",
    "        pred_boxes = torch.stack((x0, y0, z0, x1, y1, z1), dim=-1)\n",
    "\n",
    "        # Reshape to match input deltas shape (supports multiple predictions per box)\n",
    "        return pred_boxes.reshape(deltas.shape)\n",
    "\n",
    "def pairwise_intersection(boxes1: Boxes3D, boxes2: Boxes3D) -> torch.Tensor:\n",
    "\n",
    "    boxes1, boxes2 = boxes1.tensor, boxes2.tensor\n",
    "    depth_height_width = (\n",
    "        torch.min(boxes1[:, None, 3:], boxes2[:, 3:]) - \n",
    "        torch.max(boxes1[:, None, :3], boxes2[:, :3])\n",
    "    ) # (N, M, 3)\n",
    "\n",
    "    depth_height_width.clamp_(min=0)\n",
    "\n",
    "    intersection = depth_height_width.prod(dim=2) \n",
    "    return intersection\n",
    "\n",
    "def pairwise_iou_3d(boxes1: Boxes3D, boxes2: Boxes3D) -> torch.Tensor:\n",
    "\n",
    "    \"\"\"\n",
    "    Given two lists of boxes of sizes N and M computes the IoU \n",
    "    (intersection over Union) between **all** N x M pairs of boxes.\n",
    "    The box order must be (xmin, ymin, xmax, ymax).\n",
    "    \"\"\"\n",
    "\n",
    "    vol1 = boxes1.volume()\n",
    "    vol2 = boxes2.volume()\n",
    "\n",
    "    inter = pairwise_intersection(boxes1, boxes2)\n",
    "\n",
    "    iou = torch.where(\n",
    "        inter > 0,\n",
    "        inter / (vol1[:, None] + vol2 - inter),\n",
    "        torch.zeros(1, dtype=inter.dtype, device=inter.device)\n",
    "    )\n",
    "\n",
    "    return iou\n",
    "\n",
    "def _volume(boxes: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    boxes: (..., 6)\n",
    "    \"\"\"\n",
    "    return (\n",
    "        (boxes[..., 3] - boxes[..., 0]).clamp(min=0) *\n",
    "        (boxes[..., 4] - boxes[..., 1]).clamp(min=0) *\n",
    "        (boxes[..., 5] - boxes[..., 2]).clamp(min=0)\n",
    "    )\n",
    "\n",
    "def _intersection_3d(boxes1: torch.Tensor, boxes2: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    boxes1, boxes2: (..., 6)\n",
    "    \"\"\"\n",
    "    max_xyz = torch.min(boxes1[..., 3:], boxes2[..., 3:])\n",
    "    min_xyz = torch.max(boxes1[..., :3], boxes2[..., :3])\n",
    "    inter = (max_xyz - min_xyz).clamp(min=0)\n",
    "    return inter[..., 0] * inter[..., 1] * inter[..., 2]\n",
    "\n",
    "\n",
    "def _enclosing_box_3d(boxes1: torch.Tensor, boxes2: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Smallest enclosing box of boxes1 and boxes2\n",
    "    \"\"\"\n",
    "    min_xyz = torch.min(boxes1[..., :3], boxes2[..., :3])\n",
    "    max_xyz = torch.max(boxes1[..., 3:], boxes2[..., 3:])\n",
    "    return torch.cat([min_xyz, max_xyz], dim=-1)\n",
    "\n",
    "def giou_loss_3d(\n",
    "    boxes1: torch.Tensor,\n",
    "    boxes2: torch.Tensor,\n",
    "    reduction: str=\"none\",\n",
    "    eps: float = 1e-7,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    boxes1, boxes2: (N, 6)\n",
    "    \"\"\"\n",
    "\n",
    "    inter = _intersection_3d(boxes1, boxes2)\n",
    "    vol1, vol2 = _volume(boxes1), _volume(boxes2)\n",
    "\n",
    "    union = vol1 + vol2 - inter + eps\n",
    "    iou = inter / union\n",
    "\n",
    "    c = _enclosing_box_3d(boxes1, boxes2)\n",
    "    vol_c = _volume(c) + eps\n",
    "\n",
    "    giou = iou - (vol_c - union) / vol_c\n",
    "    loss = 1.0 - giou\n",
    "\n",
    "    if reduction == \"sum\":\n",
    "        return loss.sum()\n",
    "    elif reduction == \"mean\":\n",
    "        return loss.mean()\n",
    "    return loss\n",
    "\n",
    "def diou_loss_3d(\n",
    "    boxes1: torch.Tensor,\n",
    "    boxes2: torch.Tensor,\n",
    "    reduction: str = \"none\",\n",
    "    eps: float = 1e-7\n",
    "):\n",
    "\n",
    "    inter = _intersection_3d(boxes1, boxes2)\n",
    "    vol1, vol2 = _volume(boxes1), _volume(boxes2)\n",
    "\n",
    "    union = vol1 + vol2 - inter + eps\n",
    "    iou = inter / union\n",
    "\n",
    "    c1 = (boxes1[..., :3] + boxes1[..., 3:]) / 2\n",
    "    c2 = (boxes2[..., :3] + boxes2[..., 3:]) / 2\n",
    "    center_dist_sq = ((c1-c2) ** 2).sum(dim=-1)\n",
    "\n",
    "    c = _enclosing_box_3d(boxes1, boxes2)\n",
    "    diag_sq = ((c[..., 3:] - c[..., 3:]) ** 2).sum(dim=-1) + eps\n",
    "\n",
    "    diou = iou - center_dist_sq / diag_sq\n",
    "    loss = 1.0 - diou\n",
    "\n",
    "    if reduction == \"sum\":\n",
    "        return loss.sum()\n",
    "    elif reduction == \"mean\":\n",
    "        return loss.mean()\n",
    "    return loss\n",
    "\n",
    "def ciou_loss_3d(\n",
    "    boxes1: torch.Tensor,\n",
    "    boxes2: torch.Tensor,\n",
    "    reduction: str = \"none\",\n",
    "    eps: float = 1e-7,\n",
    "):\n",
    "    inter = _intersection_3d(boxes1, boxes2)\n",
    "    vol1 = _volume(boxes1)\n",
    "    vol2 = _volume(boxes2)\n",
    "\n",
    "    union = vol1 + vol2 - inter + eps\n",
    "    iou = inter / union\n",
    "\n",
    "    # centers\n",
    "    c1 = (boxes1[..., :3] + boxes1[..., 3:]) / 2\n",
    "    c2 = (boxes2[..., :3] + boxes2[..., 3:]) / 2\n",
    "    center_dist_sq = ((c1 - c2) ** 2).sum(dim=-1)\n",
    "\n",
    "    # enclosing diagonal\n",
    "    c = _enclosing_box_3d(boxes1, boxes2)\n",
    "    diag_sq = ((c[..., 3:] - c[..., :3]) ** 2).sum(dim=-1) + eps\n",
    "\n",
    "    # box dimensions\n",
    "    d1 = (boxes1[..., 3:] - boxes1[..., :3]).clamp(min=eps)\n",
    "    d2 = (boxes2[..., 3:] - boxes2[..., :3]).clamp(min=eps)\n",
    "\n",
    "    # aspect ratio consistency (3D)\n",
    "    v = (\n",
    "        (torch.atan(d1[..., 0] / d1[..., 1]) - torch.atan(d2[..., 0] / d2[..., 1])) ** 2 +\n",
    "        (torch.atan(d1[..., 1] / d1[..., 2]) - torch.atan(d2[..., 1] / d2[..., 2])) ** 2 +\n",
    "        (torch.atan(d1[..., 0] / d1[..., 2]) - torch.atan(d2[..., 0] / d2[..., 2])) ** 2\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        alpha = v / (1 - iou + v + eps)\n",
    "\n",
    "    ciou = iou - center_dist_sq / diag_sq - alpha * v\n",
    "    loss = 1.0 - ciou\n",
    "\n",
    "    if reduction == \"sum\":\n",
    "        return loss.sum()\n",
    "    elif reduction == \"mean\":\n",
    "        return loss.mean()\n",
    "    return loss\n",
    "\n",
    "def _dense_box_regression_loss_3d(\n",
    "    anchors: List[Union[Boxes3D, torch.Tensor]],\n",
    "    box3d2box3d_transform,\n",
    "    pred_anchor_deltas: List[torch.Tensor],\n",
    "    gt_boxes: List[torch.Tensor],\n",
    "    fg_mask: torch.Tensor,\n",
    "    box_reg_loss_type=\"smooth_l1\",\n",
    "    smooth_l1_beta=0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute loss for dense multi-level 3D box regression.\n",
    "    Loss is accumulated over ``fg_mask``.\n",
    "\n",
    "    Args:\n",
    "        anchors: #lvl anchor boxes, each is (HixWixA, 6)\n",
    "        pred_anchor_deltas: #lvl predictions, each is (N, HixWixA, 6)\n",
    "        gt_boxes: N ground truth boxes, each has shape (R, 6)\n",
    "        fg_mask: foreground boolean mask of shape (N, R)\n",
    "        box_reg_loss_type (str): \"smooth_l1\", \"giou\", \"diou\", \"ciou\"\n",
    "        smooth_l1_beta (float): beta for Smooth L1 loss\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate anchors across feature levels\n",
    "    if isinstance(anchors[0], Boxes3D):\n",
    "        anchors = type(anchors[0]).cat(anchors).tensor  # (R, 6)\n",
    "    else:\n",
    "        anchors = torch.cat(anchors, dim=0)  # (R, 6)\n",
    "\n",
    "    # Concatenate predictions across levels: (N, R, 6)\n",
    "    pred_anchor_deltas = torch.cat(pred_anchor_deltas, dim=1)\n",
    "\n",
    "    if box_reg_loss_type == \"smooth_l1\":\n",
    "        # Compute GT deltas\n",
    "        gt_anchor_deltas = [\n",
    "            box3d2box3d_transform.get_deltas(anchors, k)\n",
    "            for k in gt_boxes\n",
    "        ]\n",
    "        gt_anchor_deltas = torch.stack(gt_anchor_deltas)  # (N, R, 6)\n",
    "\n",
    "        loss_box_reg = smooth_l1_loss(\n",
    "            pred_anchor_deltas[fg_mask],\n",
    "            gt_anchor_deltas[fg_mask],\n",
    "            beta=smooth_l1_beta,\n",
    "            reduction=\"sum\",\n",
    "        )\n",
    "\n",
    "    elif box_reg_loss_type in {\"giou\", \"diou\", \"ciou\"}:\n",
    "        # Decode predicted boxes\n",
    "        pred_boxes = [\n",
    "            box3d2box3d_transform.apply_deltas(d, anchors)\n",
    "            for d in pred_anchor_deltas\n",
    "        ]  # list of (R, 6)\n",
    "\n",
    "        pred_boxes = torch.stack(pred_boxes)  # (N, R, 6)\n",
    "        gt_boxes = torch.stack(gt_boxes)      # (N, R, 6)\n",
    "\n",
    "        if box_reg_loss_type == \"giou\":\n",
    "            loss_box_reg = giou_loss_3d(\n",
    "                pred_boxes[fg_mask],\n",
    "                gt_boxes[fg_mask],\n",
    "                reduction=\"sum\",\n",
    "            )\n",
    "        elif box_reg_loss_type == \"diou\":\n",
    "            loss_box_reg = diou_loss_3d(\n",
    "                pred_boxes[fg_mask],\n",
    "                gt_boxes[fg_mask],\n",
    "                reduction=\"sum\",\n",
    "            )\n",
    "        else:  # ciou\n",
    "            loss_box_reg = ciou_loss_3d(\n",
    "                pred_boxes[fg_mask],\n",
    "                gt_boxes[fg_mask],\n",
    "                reduction=\"sum\",\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid dense box regression loss type '{box_reg_loss_type}'\")\n",
    "\n",
    "    return loss_box_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd266047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qct_nod_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
