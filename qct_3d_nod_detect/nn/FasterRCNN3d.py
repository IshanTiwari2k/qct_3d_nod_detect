# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/training/22_nn.ipynb.

# %% auto 0
__all__ = ['GeneralizedRCNN3D', 'build_targets', 'build_image_list_3d', 'build_instances_3d']

# %% ../../nbs/training/22_nn.ipynb 0
import torch.nn as nn
import torch

from typing import (
    Optional, 
    List, 
    Dict
)

from qct_3d_nod_detect.structures import (
    Boxes3D, 
    Instances3D,
    ImagesList3D
)

class GeneralizedRCNN3D(nn.Module):

    def __init__(
            self,
            backbone: nn.Module,
            rpn: nn.Module,
            roi_heads: nn.Module,
    ):

        super().__init__()
        self.backbone = backbone
        self.rpn = rpn
        self.roi_heads = roi_heads

    def forward_train(
            self,
            images: torch.Tensor,
            targets: Optional[List[Instances3D]] = None,
    ) -> Dict[str, torch.Tensor]:
        
        """
        Returns:
            training: dict of losses
            inference: List[Instances3D]
        """

        images_dict = {"chest_ct": images}
        features: Dict[str, torch.Tensor] = self.backbone(images_dict)

        image_list = ImagesList3D(
                tensor=images,
                image_sizes=[images.shape[-3:]] * images.shape[0],
            )
            
        proposals, rpn_losses, rpn_stats = self.rpn(
            images=image_list,
            features=features,
            gt_instances=targets,
            training=True,
        )

        roi_losses = self.roi_heads(
            features=features,
            proposals=proposals,
            targets=targets,
            training=True
        )

        return {
            "losses" : {
                **rpn_losses,
                **roi_losses,
            },
            "stats": {
                **rpn_stats
            }
        }
    
    @torch.no_grad()
    def forward_inference(
        self,
        images: torch.Tensor,
    ) -> List[Instances3D]:
        images_dict = {"chest_ct": images}
        features = self.backbone(images_dict)

        image_list = ImagesList3D(
                tensor=images,
                image_sizes=[images.shape[-3:]] * images.shape[0],
        )

        proposals, _, _ = self.rpn(
            images=image_list,
            features=features,
            gt_instances=None,
            training=False,
        )

        detections = self.roi_heads(
            features=features,
            proposals=proposals,
            targets=None,
            training=False
        )

        return detections

def build_targets(batch):
    targets = []

    B = len(batch["gt_boxes"])
    image_size = batch["image"].shape[-3:]

    for i in range(B):
        inst = Instances3D(image_size=image_size)
        inst.gt_boxes = Boxes3D(batch["gt_boxes"][i])
        inst.gt_classes = batch["gt_classes"][i].long()
        targets.append(inst)

    return targets

def build_image_list_3d(images: torch.Tensor) -> ImagesList3D:
    """
    Args:
        images: Tensor[B, C, D, H, W]
    """
    image_sizes = [tuple(images.shape[-3:]) for _ in range(images.shape[0])]
    return ImagesList3D(image_sizes)

def build_instances_3d(batch):
    instances = []

    for boxes, classes in zip(batch["gt_boxes"], batch["gt_classes"]):
        inst = Instances3D(image_size=batch["image"].shape[-3:])
        inst.gt_boxes = Boxes3D(boxes)
        inst.gt_classes = classes
        instances.append(inst)

    return instances