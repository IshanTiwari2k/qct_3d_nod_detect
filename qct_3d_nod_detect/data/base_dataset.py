# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/data/detection_dataloader.ipynb.

# %% auto 0
__all__ = ['DetDataset']

# %% ../../nbs/data/detection_dataloader.ipynb 2
from torch.utils.data import Dataset
from typing import List, Tuple, Dict
import torch
import loguru
from pathlib import Path
from safetensors.torch import load_file
from .configs import DetDatasetConfig
from ..utils import cccwhd_to_corners
import pandas as pd
import numpy as np
import nibabel as nib
import torch.nn.functional as F

class DetDataset(Dataset):

    def __init__(self, cfg: DetDatasetConfig):

        super().__init__()

        self.patch_size = cfg.patch_size
        self.split = cfg.split
        self.centers_to_exclude = cfg.centers_to_exclude
        self.windows = cfg.windows
        self.cache_root_path = cfg.cache_root_path
        self.master_csv = pd.read_csv(Path(cfg.cache_root_path) / "master_csv.csv")

        self.master_csv = self.master_csv[
            (self.master_csv["scan_annot_type"] == cfg.scan_annot_type)
            & (self.master_csv["annotated_by"] == cfg.annotated_by)
            & (
                 ~self.master_csv["mongo_collection_name"].isin(
                    cfg.centers_to_exclude
                )
            )
            & (self.master_csv["data_split"] == cfg.split)
        ]

        self.master_csv = self.master_csv.dropna(subset=["nodule_bbox"])

        self.sid_to_center = {}
        self.sid_to_bboxes = {}

        grouped = self.master_csv.groupby("series_uid")

        grouped = self.master_csv.groupby("series_uid")
        for sid, sid_rows in grouped:
            mongo_collection_name = sid_rows.iloc[0]["mongo_collection_name"]
            self.sid_to_center[sid] = mongo_collection_name

            gt_bboxes = []
            for _, row in sid_rows.iterrows():
                nodule_bbox = eval(row["nodule_bbox"])
                bbox = self.get_bbox_coords_from_dic(nodule_bbox)
                gt_bboxes.append(bbox)

            if len(gt_bboxes) > 0:
                self.sid_to_bboxes[sid] = gt_bboxes

        self.sids = list(self.master_csv["series_uid"].unique())
        self.sids = [sid for sid in self.sids if sid in self.sid_to_bboxes]

        num_scans = len(self.master_csv["series_uid"].unique())
        loguru.logger.info(f"{self.split.upper()} Number of scans used - {num_scans}")
        loguru.logger.info(
            f"{self.split.upper()} Number of nodules - {len(self.master_csv)}\n"
        )

    @staticmethod
    def apply_windowing(
        img: torch.Tensor,
        windows: List[Dict[str, float]],
        normalize: bool = True,
    ) -> torch.Tensor:

        """
        Apply multiple window level/width transforms to a 3D image.

        Args:
            img: Tensor of shape (D, H, W), typically CT in HU.
            windows: list of dicts, each with:
                - 'wl' (window level / center)
                - 'ww' (window width)
            normalize: if True → outputs in [0, 1], else → only clipping.

        Returns:
            Tensor of shape (Win, D, H, W)
        """

        assert img.ndim == 3, f"Expected img of shape (D, H, W), got {img.shape}"

        device = img.device
        dtype = img.dtype
        win_count = len(windows)

        if win_count == 0:
            raise ValueError("windows list is empty.")

        wl = torch.tensor([w["wl"] for w in windows], device=device, dtype=dtype)
        ww = torch.tensor([w["ww"] for w in windows], device=device, dtype=dtype)

        low = wl - ww / 2.0
        high = wl + ww / 2.0

        low = low.view(win_count, 1, 1, 1)
        high = high.view(win_count, 1, 1, 1)

        img_expanded = img.unsqueeze(0)
        windowed = torch.clamp(img_expanded, min=low, max=high)

        if normalize:
            windowed = (windowed - low) / (high - low)

        return windowed

    @staticmethod
    def get_bbox_coords_from_dic(nodule_bbox: dict):

        """Convert the dictionary gt to cccxyz format (xc, yc, zc, w, h, d)"""

        xc, yc, zc = nodule_bbox["xc"], nodule_bbox["yc"], nodule_bbox["zc"]
        w, h, d = nodule_bbox["w"], nodule_bbox["h"], nodule_bbox["d"]
        return (xc, yc, zc, w, h, d)

    @staticmethod
    def random_nodule_patch_detection(
        volume: torch.Tensor,
        gt_boxes: List[Tuple[float, float, float, float, float, float]],
        patch_size: Tuple[int, int, int],
        rng: torch.Generator = None,
    ):

        if rng is None:
            rng = torch.default_generator

        if volume.ndim == 3:
            D, H, W = volume.shape
            leading = ()

        elif volume.ndim == 4:
            _, D, H, W = volume.shape
            leading = (slice(None), )
        
        else:
            raise ValueError(volume.shape)

        Dz, Dy, Dx = patch_size

        anchor_idx = int(torch.randint(0, len(gt_boxes), (1,), generator=rng))
        xc, yc, zc, _, _, _ = gt_boxes[anchor_idx]
        xc, yc, zc = map(lambda x: int(round(x)), (xc, yc, zc))

        def sample_start(c, size, max_dim):

            low = max(0, c-size+1)
            high = min(c, max_dim-size)

            if low>high:
                low = high = max(0, min(c, max_dim-size))

            return int(torch.randint(low, high + 1, (1,), generator=rng))

        z0 = sample_start(zc, Dz, D)
        y0 = sample_start(yc, Dy, H)
        x0 = sample_start(xc, Dx, W)

        z1, y1, x1 = z0 + Dz, y0 + Dy, x0 + Dx

        patch = volume[leading + (slice(z0, z1), slice(y0, y1), slice(x0, x1))]

        new_boxes = []
        for box in gt_boxes:
            bx0, by0, bz0, bx1, by1, bz1 = cccwhd_to_corners(box)

            # intersection with patch
            ix0 = max(bx0, x0)
            iy0 = max(by0, y0)
            iz0 = max(bz0, z0)
            ix1 = min(bx1, x1)
            iy1 = min(by1, y1)
            iz1 = min(bz1, z1)

            if ix1 <= ix0 or iy1 <= iy0 or iz1 <= iz0:
                continue  # no overlap

            # shift to patch coordinates
            ix0 -= x0
            iy0 -= y0
            iz0 -= z0
            ix1 -= x0
            iy1 -= y0
            iz1 -= z0

            new_boxes.append((ix0, iy0, iz0, ix1, iy1, iz1))

        if len(new_boxes) == 0:
            raise RuntimeError("Crop lost all GT boxes — should not happen")

        return patch, new_boxes

    def get_scan_mask_path(self, sid: str) -> Path:

        mongo_collection_name = self.sid_to_center[sid]

        root_path = Path(self.cache_root_path).parent

        image_path = (
            root_path / "full_resolution/"
            f"{mongo_collection_name}/{sid}.safetensor"
        )
        lung_mask_path = (
            f"{self.cache_root_path}/annotations/lung_masks/"
            f"{mongo_collection_name}/{sid}.nii.gz"
        )
        nodule_mask_path = (
            f"{self.cache_root_path}/annotations/nodule_masks/"
            f"full_annot/full_resolution/{mongo_collection_name}/"
            f"{self.split}/{sid}.nii.gz"
        )

        return image_path, lung_mask_path, nodule_mask_path
    
    @staticmethod
    def pad_scan(
        scan: torch.Tensor,
        patch_size: Tuple[int, int, int],
    ):
        """
        Pad scan so that at least one patch of patch_size can be extracted.
        """
        assert scan.ndim == 3, f"Expected scan (D,H,W), got {scan.shape}"

        D, H, W = scan.shape
        Dz, Dy, Dx = patch_size

        pad_z = max(0, Dz - D)
        pad_y = max(0, Dy - H)
        pad_x = max(0, Dx - W)

        if pad_z == pad_y == pad_x == 0:
            return scan

        scan_padded = F.pad(
            scan,
            (0, pad_x, 0, pad_y, 0, pad_z),
            mode="constant",
            value=0,
        )

        return scan_padded

    def __getitem__(self, idx):

        scan_sid = self.sids[idx]

        image_path, _, _ = self.get_scan_mask_path(
            sid=scan_sid
        )

        try:
            scan = load_file(image_path)["ct_data"]  # (D,H,W)
        except Exception as e:
            print(e)
            return "invalid"

        gt_boxes_full = self.sid_to_bboxes[scan_sid]
        if len(gt_boxes_full) == 0:
            return "invalid"

        # ---- pad scan + masks
        scan = self.pad_scan(
            scan=scan,
            patch_size=self.patch_size,
        )

        patch, patch_boxes_corner = self.random_nodule_patch_detection(
            volume=scan,
            gt_boxes=gt_boxes_full,
            patch_size=self.patch_size,
        )

        # ---- windowing
        image = self.apply_windowing(
            img=patch, windows=self.windows
        )  # (C,D,H,W)

        gt_boxes = torch.tensor(patch_boxes_corner, dtype=torch.float32)
        gt_classes = torch.zeros(len(gt_boxes), dtype=torch.int64)

        return {
            "image": image,        # Tensor[C,D,H,W]
            "gt_boxes": gt_boxes,  # Tensor[N,6] (cccwhd)
            "gt_classes": gt_classes
        }

    def __len__(self):
        return len(self.sids)