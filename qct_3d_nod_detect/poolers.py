# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_poolers.ipynb.

# %% auto 0
__all__ = ['assign_boxes_to_levels_3d', 'convert_boxes_to_pooler_format_3d', 'RoIPool3D', 'ROIAlign3D', 'ROIPooler3D']

# %% ../nbs/01_poolers.ipynb 0
import math
from typing import List, Optional, Tuple
import torch
from torch import Tensor
from torch import nn
import torch.nn.functional as F
from .layers import nonzero_tuple, cat, shapes_to_tensor
from .structures import Boxes3D, Instances3D

# %% ../nbs/01_poolers.ipynb 1
def assign_boxes_to_levels_3d(
        box_lists: List[Boxes3D],
        min_level: int,
        max_level: int,
        canonical_box_size: float = 224.0,
        canonical_level: int = 4,
) -> torch.Tensor:

    volumes = torch.cat([b.volume() for b in box_lists])
    box_sizes = volumes ** (1.0 / 3.0)

    level_assignments = torch.floor(
        canonical_level + torch.log2(box_sizes / canonical_box_size + 1e-6)
    )

    level_assignments = torch.clamp(level_assignments, min=min_level, max=max_level)
    return (level_assignments - min_level).to(torch.int64)

def _convert_boxes_to_pooler_format_3d(boxes: Tensor, sizes: Tensor) -> Tensor:
    """
    Low-level helper: prepends batch indices to the box coordinates.

    Args:
        boxes: (M_total, 6) tensor of [x1,y1,z1, x2,y2,z2]
        sizes: (B,) tensor with number of boxes per image

    Returns:
        (M_total, 7) tensor of [batch_idx, x1,y1,z1, x2,y2,z2]
    """
    sizes = sizes.to(device=boxes.device)
    indices = torch.repeat_interleave(
        torch.arange(len(sizes), dtype=boxes.dtype, device=boxes.device),
        sizes
    )
    return cat([indices[:, None], boxes], dim=1)

def convert_boxes_to_pooler_format_3d(box_lists: List[Boxes3D]) -> Tensor:
    """
    Convert a list of per-image 3D box objects into the format expected by
    3D RoI pooling / alignment operations.

    Compatible with:
    - Boxes3D.tensor: [x1, y1, z1, x2, y2, z2] (min/max corners)
    - ROIAlign3D / RoIPool3D expecting [batch_idx, x1,y1,z1, x2,y2,z2]

    Args:
        box_lists (List[Boxes3D]):
            List of N Boxes3D objects (N = batch size).
            Each Boxes3D has .tensor of shape (num_boxes_i, 6)

    Returns:
        Tensor of shape (M, 7), where M is total number of boxes across batch.
        Columns: [batch_index, x1, y1, z1, x2, y2, z2]
    """
    if len(box_lists) == 0:
        # Return empty tensor with correct dtype/device
        return torch.empty((0, 7), dtype=torch.float32, device=torch.device("cpu"))

    # Concatenate all box tensors from all images
    all_boxes = torch.cat([b.tensor for b in box_lists], dim=0)  # (M_total, 6)

    # Get number of boxes per image (tracing-friendly)
    sizes = shapes_to_tensor([len(b) for b in box_lists], device=all_boxes.device)

    return _convert_boxes_to_pooler_format_3d(all_boxes, sizes)

class RoIPool3D(nn.Module):
    """
    3D ROI Pooling module.

    Args:
        output_size (tuple[int]): (out_d, out_h, out_w), size of the output feature map
    """

    def __init__(self, output_size: Tuple[int, int, int]):
        super().__init__()
        self.output_size = output_size

    def forward(self, features: torch.Tensor, rois: torch.Tensor) -> torch.Tensor:
        """
        Args:
            features (Tensor[N, C, D, H, W]): input volumetric feature maps
            rois (Tensor[num_rois, 7]): ROI boxes with (batch_idx, z1, y1, x1, z2, y2, x2)
                coordinates must be in **feature map scale**.

        Returns:
            Tensor[num_rois, C, out_d, out_h, out_w]: pooled features
        """
        num_rois = rois.size(0)
        N, C, _, _, _ = features.shape
        out_d, out_h, out_w = self.output_size

        pooled = torch.zeros(
            (num_rois, C, out_d, out_h, out_w),
            device=features.device,
            dtype=features.dtype,
        )

        for i in range(num_rois):
            batch_idx = int(rois[i, 0])
            z1, y1, x1, z2, y2, x2 = rois[i, 1:]

            # Crop ROI and apply adaptive max pooling
            roi_feature = features[
                batch_idx : batch_idx + 1,
                :,
                int(z1):int(z2),
                int(y1):int(y2),
                int(x1):int(x2),
            ]

            pooled[i] = F.adaptive_max_pool3d(roi_feature, self.output_size)

        return pooled

class ROIAlign3D(nn.Module):
    def __init__(self, output_size, spatial_scale, sampling_ratio=-1, aligned=True):
        """
        3D ROIAlign: trilinear align.

        Args:
            output_size (tuple): (out_d, out_h, out_w)
            spatial_scale (float): scale bar for the input boxes
            sampling_ratio (int): number of grid samples per output bin (<=0 means adaptive)
            aligned (bool): if True, use the same alignment strategy as Detectron2
        """
        super().__init__()
        self.output_size = output_size
        self.spatial_scale = spatial_scale
        self.sampling_ratio = sampling_ratio
        self.aligned = aligned

    def forward(self, input: torch.Tensor, rois: torch.Tensor):
        """
        Args:
            input: (N, C, D, H, W)
            rois: (num_rois, 7) = (batch_idx, x1,y1,z1,x2,y2,z2)
        """
        assert rois.dim() == 2 and rois.size(1) == 7

        num_rois = rois.size(0)
        output = []

        N, C, D, H, W = input.shape
        out_d, out_h, out_w = self.output_size

        for i in range(num_rois):
            batch_idx = int(rois[i, 0].item())
            x1, y1, z1, x2, y2, z2 = rois[i, 1:] * self.spatial_scale

            if self.aligned:
                # coordinate shift for correct alignment
                x1 -= 0.5
                y1 -= 0.5
                z1 -= 0.5
                x2 -= 0.5
                y2 -= 0.5
                z2 -= 0.5

            # voxel grid spacing
            d_step = (z2 - z1) / max(out_d, 1)
            h_step = (y2 - y1) / max(out_h, 1)
            w_step = (x2 - x1) / max(out_w, 1)

            # Construct a sampling grid
            d = torch.linspace(z1 + 0.5 * d_step, z2 - 0.5 * d_step, out_d, device=input.device)
            h = torch.linspace(y1 + 0.5 * h_step, y2 - 0.5 * h_step, out_h, device=input.device)
            w = torch.linspace(x1 + 0.5 * w_step, x2 - 0.5 * w_step, out_w, device=input.device)

            grid_d, grid_h, grid_w = torch.meshgrid(d, h, w, indexing="ij")

            # Normalize to [-1,1] in each dimension
            grid = torch.stack((grid_w / (W - 1) * 2 - 1,
                                grid_h / (H - 1) * 2 - 1,
                                grid_d / (D - 1) * 2 - 1), dim=-1)

            grid = grid.unsqueeze(0)  # (1, out_d, out_h, out_w, 3)

            # Sample with trilinear interpolation
            roi_feat = F.grid_sample(
                input[batch_idx : batch_idx + 1],  # shape (1, C, D, H, W)
                grid,
                mode="bilinear",
                padding_mode="zeros",
                align_corners=True,
            )

            output.append(roi_feat)

        return torch.cat(output, dim=0)  # (num_rois, C, out_d, out_h, out_w)

    def __repr__(self):
        return (
            f"{self.__class__.__name__}("
            f"output_size={self.output_size}, "
            f"spatial_scale={self.spatial_scale}, "
            f"sampling_ratio={self.sampling_ratio}, "
            f"aligned={self.aligned}"
            f")"
        )

# %% ../nbs/01_poolers.ipynb 2
class ROIPooler3D(nn.Module):

    def __init__(
        self,
        output_size: Tuple[int, int, int],
        scales: List[float],
        sampling_ratio: int = 0,
        pooler_type: str = "ROIAlignV2",
        canonical_box_size: float = 224.0,
        canonical_level: int = 4,
    ):
        super().__init__()
        if isinstance(output_size, int):
            output_size = (output_size, output_size, output_size)

        self.output_size = output_size
        self.canonical_box_size = canonical_box_size
        self.canonical_level = canonical_level

        # Compute levels from scales (stride = 1/scale, assume power of 2)
        scales = sorted(scales)[::-1]
        strides = [1.0 / s for s in scales]
        min_level = int(round(math.log2(strides[0])))
        max_level = int(round(math.log2(strides[-1])))

        assert max_level - min_level + 1 == len(scales)

        self.min_level = min_level
        self.max_level = max_level

        # Create per level poolers
        for scale in scales:
            if pooler_type == "ROIAlign3D":
                self.level_poolers = nn.ModuleList(
                    ROIAlign3D(
                        output_size,
                        spatial_scale=scale,
                        sampling_ratio=sampling_ratio,
                        aligned=False,
                    )
                    for scale in scales
                )

            elif pooler_type == "ROIALign3DV2":
                self.level_poolers = nn.ModuleList(
                    ROIAlign3D(
                        output_size,
                        spatial_scale=scale,
                        sampling_ratio=sampling_ratio,
                        aligned=True,
                    )
                    for scale in scales
                )

            elif pooler_type == "ROIPool3D":
                self.level_poolers = nn.ModuleList(
                    RoIPool3D(output_size)
                    for scale in scales
                )

            else:
                raise ValueError(f"Unknown pooler type: {pooler_type}")

            self.pooler_type = pooler_type

    def forward(
            self, 
            x: List[torch.Tensor], 
            box_lists: List[Boxes3D]
        ) -> torch.Tensor:

            """
            Args:

            x: List[Tensor]      [ (B,C,D,H,W), (B,C,D/2,H/2,W/2), ... ]
            box_lists: List[Boxes3D]  per image, usually list of length B
            """

            pooler_fmt_boxes = convert_boxes_to_pooler_format_3d(box_lists)

            if len(box_lists) == 0:
                return torch.zeros((0, x[0].shape[1], *self.output_size), device=x[0].device)

            # Mutli_level box assignment
            level_assignments = assign_boxes_to_levels_3d(
                box_lists,
                self.min_level,
                self.max_level,
                self.canonical_box_size,
                self.canonical_level,
            )

            num_channels = x[0].shape[1]
            output = torch.zeros(
                (pooler_fmt_boxes.shape[0], num_channels, *self.output_size),
                dtype=x[0].dtype, device=x[0].device
            )

            for lvl, pooler in enumerate(self.level_poolers):
                inds = (level_assignments == lvl).nonzero(as_tuple=True)[0]
                if len(inds) == 0:
                    continue
                boxes_lvl = pooler_fmt_boxes[inds]
                feat_lvl = pooler(x[lvl], boxes_lvl)
                output.index_put_((inds,), feat_lvl)

            return output